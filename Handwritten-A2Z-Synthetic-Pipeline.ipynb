{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX5jH99nopnR"
      },
      "source": [
        "# Handwritten Character Recognition Dataset Generator\n",
        "\n",
        "This notebook generates a synthetic dataset for OCR focusing on uppercase letters A-Z with advanced data augmentation techniques for robust CNN training.\n",
        "\n",
        "## Pipeline Overview:\n",
        "1. **Font Acquisition**: Automatic download of handwriting fonts via Fontsource API\n",
        "2. **Image Generation**: Synthetic character images (28x28 grayscale) with augmentation\n",
        "3. **Class Balancing**: Automatic handling of underrepresented/overrepresented characters\n",
        "4. **Export**: Organized dataset structure ready for CNN training\n",
        "\n",
        "## Output Specifications:\n",
        "- Image size: 28x28 pixels (grayscale mode 'L')\n",
        "- Background: Light (220-255), Text: Dark (0-50)\n",
        "- Augmentations: Rotation, translation, scale, stroke width, blur, noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0eNcA9uehqL",
        "outputId": "18e96054-0b12-4ca9-fc50-587fb20ea7ce"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MODULE: AUTOMATIC HANDWRITTEN FONT ACQUISITION VIA FONTSOURCE API\n",
        "# =============================================================================\n",
        "# This module automatically downloads handwritten-style fonts from the public\n",
        "# Fontsource API without requiring an API key.\n",
        "#\n",
        "# Workflow:\n",
        "#   1. GET request to Fontsource API to retrieve font catalog\n",
        "#   2. Filter fonts by 'handwriting' category\n",
        "#   3. Download .ttf files (prioritizing Latin subset)\n",
        "#   4. Save to ./handwritten_fonts directory\n",
        "#\n",
        "# Dependencies: requests, tqdm\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Optional, Any\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Install tqdm if not available\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    subprocess.check_call(['pip', 'install', 'tqdm'])\n",
        "    from tqdm import tqdm\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CONFIGURATION\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Fontsource API endpoint\n",
        "FONTSOURCE_API_URL = \"https://api.fontsource.org/v1/fonts\"\n",
        "\n",
        "# Output directory for downloaded fonts\n",
        "FONTS_OUTPUT_DIR = \"./handwritten_fonts\"\n",
        "\n",
        "# Maximum number of fonts to download (None = all)\n",
        "MAX_FONTS_TO_DOWNLOAD = None\n",
        "\n",
        "# Preferred font subsets (in priority order)\n",
        "PREFERRED_SUBSETS = ['latin', 'latin-ext']\n",
        "\n",
        "# Preferred font weight (regular = 400)\n",
        "PREFERRED_WEIGHT = 400\n",
        "\n",
        "# Number of threads for parallel downloading\n",
        "DOWNLOAD_THREADS = 4\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# FONT ACQUISITION FUNCTIONS\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def fetch_fonts_catalog() -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Fetch complete font catalog from Fontsource API.\n",
        "\n",
        "    This function performs a GET request to the main API endpoint and\n",
        "    returns the complete list of available fonts.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: List of dictionaries containing font metadata.\n",
        "\n",
        "    Raises:\n",
        "        requests.RequestException: On connection error or HTTP error response.\n",
        "    \"\"\"\n",
        "    print(\"[INFO] Connecting to Fontsource API...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(FONTSOURCE_API_URL, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        fonts_data = response.json()\n",
        "        print(f\"[OK] Catalog retrieved: {len(fonts_data)} fonts available\")\n",
        "\n",
        "        return fonts_data\n",
        "\n",
        "    except requests.Timeout:\n",
        "        print(\"[ERROR] Timeout while connecting to Fontsource API\")\n",
        "        raise\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"[ERROR] API request failed: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def filter_handwriting_fonts(fonts_catalog: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Filter catalog to keep only handwriting-style fonts.\n",
        "\n",
        "    Args:\n",
        "        fonts_catalog (List[Dict]): Complete font catalog.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: Filtered list of handwriting fonts only.\n",
        "    \"\"\"\n",
        "    handwriting_fonts = [\n",
        "        font for font in fonts_catalog\n",
        "        if font.get('category', '').lower() == 'handwriting'\n",
        "    ]\n",
        "\n",
        "    print(f\"[INFO] Handwriting fonts found: {len(handwriting_fonts)}\")\n",
        "\n",
        "    return handwriting_fonts\n",
        "\n",
        "\n",
        "def get_font_download_url(font_id: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Retrieve TTF file download URL for a given font.\n",
        "\n",
        "    This function queries the detailed font endpoint to obtain download links,\n",
        "    prioritizing the 'latin' subset.\n",
        "\n",
        "    Args:\n",
        "        font_id (str): Unique font identifier on Fontsource.\n",
        "\n",
        "    Returns:\n",
        "        Optional[str]: TTF file URL or None if not available.\n",
        "    \"\"\"\n",
        "    detail_url = f\"{FONTSOURCE_API_URL}/{font_id}\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(detail_url, timeout=15)\n",
        "        response.raise_for_status()\n",
        "        font_detail = response.json()\n",
        "\n",
        "        # Get available variants\n",
        "        variants = font_detail.get('variants', {})\n",
        "\n",
        "        # Look for preferred weight (400 = regular)\n",
        "        weight_key = str(PREFERRED_WEIGHT)\n",
        "        if weight_key not in variants:\n",
        "            # Take first available weight\n",
        "            if variants:\n",
        "                weight_key = list(variants.keys())[0]\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "        weight_variants = variants.get(weight_key, {})\n",
        "\n",
        "        # Look for normal style\n",
        "        style_variants = weight_variants.get('normal', {})\n",
        "        if not style_variants:\n",
        "            # Try italic if normal not available\n",
        "            style_variants = weight_variants.get('italic', {})\n",
        "\n",
        "        if not style_variants:\n",
        "            return None\n",
        "\n",
        "        # Search for preferred subset\n",
        "        for subset in PREFERRED_SUBSETS:\n",
        "            if subset in style_variants:\n",
        "                subset_data = style_variants[subset]\n",
        "                # TTF file URL\n",
        "                ttf_url = subset_data.get('url', {}).get('ttf')\n",
        "                if ttf_url:\n",
        "                    return ttf_url\n",
        "\n",
        "        # Fallback: take first available subset\n",
        "        if style_variants:\n",
        "            first_subset = list(style_variants.keys())[0]\n",
        "            subset_data = style_variants[first_subset]\n",
        "            return subset_data.get('url', {}).get('ttf')\n",
        "\n",
        "        return None\n",
        "\n",
        "    except requests.RequestException:\n",
        "        return None\n",
        "\n",
        "\n",
        "def download_font_file(\n",
        "    font_info: Dict[str, Any],\n",
        "    output_dir: str\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Download a TTF font file and save it locally.\n",
        "\n",
        "    Args:\n",
        "        font_info (Dict): Dictionary containing font information.\n",
        "        output_dir (str): Destination directory.\n",
        "\n",
        "    Returns:\n",
        "        Optional[str]: Path to downloaded file or None on failure.\n",
        "    \"\"\"\n",
        "    font_id = font_info.get('id', '')\n",
        "    font_family = font_info.get('family', font_id)\n",
        "\n",
        "    try:\n",
        "        # Get download URL\n",
        "        download_url = get_font_download_url(font_id)\n",
        "\n",
        "        if not download_url:\n",
        "            return None\n",
        "\n",
        "        # Download file\n",
        "        response = requests.get(download_url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Create clean filename\n",
        "        safe_name = \"\".join(c if c.isalnum() or c in '-_' else '_' for c in font_family)\n",
        "        filename = f\"{safe_name}.ttf\"\n",
        "        filepath = Path(output_dir) / filename\n",
        "\n",
        "        # Save file\n",
        "        with open(filepath, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        return str(filepath)\n",
        "\n",
        "    except requests.RequestException:\n",
        "        return None\n",
        "    except IOError:\n",
        "        return None\n",
        "\n",
        "\n",
        "def download_handwriting_fonts(\n",
        "    max_fonts: Optional[int] = None,\n",
        "    output_dir: str = FONTS_OUTPUT_DIR,\n",
        "    num_threads: int = DOWNLOAD_THREADS\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Main function to download handwriting fonts.\n",
        "\n",
        "    This function orchestrates the complete process:\n",
        "    1. Retrieve Fontsource catalog\n",
        "    2. Filter handwriting fonts\n",
        "    3. Parallel download of TTF files\n",
        "\n",
        "    Args:\n",
        "        max_fonts (Optional[int]): Maximum number of fonts to download.\n",
        "        output_dir (str): Destination directory.\n",
        "        num_threads (int): Number of threads for parallel downloading.\n",
        "\n",
        "    Returns:\n",
        "        Dict: Download statistics (successes, failures, paths).\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"HANDWRITTEN FONT ACQUISITION VIA FONTSOURCE API\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Create output directory\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Statistics\n",
        "    stats = {\n",
        "        'total_available': 0,\n",
        "        'total_attempted': 0,\n",
        "        'successful': 0,\n",
        "        'failed': 0,\n",
        "        'downloaded_fonts': [],\n",
        "        'failed_fonts': []\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Step 1: Retrieve catalog\n",
        "        fonts_catalog = fetch_fonts_catalog()\n",
        "\n",
        "        # Step 2: Filter handwriting fonts\n",
        "        handwriting_fonts = filter_handwriting_fonts(fonts_catalog)\n",
        "        stats['total_available'] = len(handwriting_fonts)\n",
        "\n",
        "        if not handwriting_fonts:\n",
        "            print(\"[WARNING] No handwriting fonts found in catalog\")\n",
        "            return stats\n",
        "\n",
        "        # Limit number of fonts if specified\n",
        "        fonts_to_download = handwriting_fonts\n",
        "        if max_fonts and max_fonts < len(fonts_to_download):\n",
        "            fonts_to_download = fonts_to_download[:max_fonts]\n",
        "            print(f\"[INFO] Limited to {max_fonts} fonts (out of {len(handwriting_fonts)} available)\")\n",
        "\n",
        "        stats['total_attempted'] = len(fonts_to_download)\n",
        "\n",
        "        # Step 3: Parallel download with progress bar\n",
        "        print(f\"\\n[DOWNLOAD] Starting download of {len(fonts_to_download)} fonts...\")\n",
        "        print(f\"[INFO] Using {num_threads} parallel threads\")\n",
        "        print(f\"[INFO] Destination: {output_path.absolute()}\\n\")\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "            # Submit all download tasks\n",
        "            future_to_font = {\n",
        "                executor.submit(download_font_file, font, output_dir): font\n",
        "                for font in fonts_to_download\n",
        "            }\n",
        "\n",
        "            # Track progress with tqdm\n",
        "            with tqdm(total=len(fonts_to_download), desc=\"Download\", unit=\"font\") as pbar:\n",
        "                for future in as_completed(future_to_font):\n",
        "                    font = future_to_font[future]\n",
        "                    font_name = font.get('family', font.get('id', 'Unknown'))\n",
        "\n",
        "                    try:\n",
        "                        result = future.result()\n",
        "                        if result:\n",
        "                            stats['successful'] += 1\n",
        "                            stats['downloaded_fonts'].append({\n",
        "                                'name': font_name,\n",
        "                                'path': result\n",
        "                            })\n",
        "                        else:\n",
        "                            stats['failed'] += 1\n",
        "                            stats['failed_fonts'].append(font_name)\n",
        "                    except Exception:\n",
        "                        stats['failed'] += 1\n",
        "                        stats['failed_fonts'].append(font_name)\n",
        "\n",
        "                    pbar.update(1)\n",
        "\n",
        "        # Display summary\n",
        "        print(\"\\n\" + \"-\" * 70)\n",
        "        print(\"[DOWNLOAD SUMMARY]\")\n",
        "        print(f\"  - Handwriting fonts available: {stats['total_available']}\")\n",
        "        print(f\"  - Download attempts: {stats['total_attempted']}\")\n",
        "        print(f\"  - Successful downloads: {stats['successful']}\")\n",
        "        print(f\"  - Failed downloads: {stats['failed']}\")\n",
        "        print(f\"  - Output directory: {output_path.absolute()}\")\n",
        "\n",
        "        if stats['successful'] > 0:\n",
        "            print(f\"\\n[OK] {stats['successful']} handwriting fonts ready for use\")\n",
        "        else:\n",
        "            print(\"\\n[WARNING] No fonts could be downloaded\")\n",
        "\n",
        "        print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "        return stats\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[CRITICAL ERROR] {e}\")\n",
        "        return stats\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# EXECUTE DOWNLOAD\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Check if fonts already exist\n",
        "existing_fonts = list(Path(FONTS_OUTPUT_DIR).glob(\"*.ttf\")) if Path(FONTS_OUTPUT_DIR).exists() else []\n",
        "\n",
        "if existing_fonts:\n",
        "    print(f\"[INFO] {len(existing_fonts)} fonts already present in '{FONTS_OUTPUT_DIR}'\")\n",
        "    user_choice = input(\"Do you want to download additional fonts? (y/n): \").strip().lower()\n",
        "\n",
        "    if user_choice == 'y':\n",
        "        download_stats = download_handwriting_fonts(\n",
        "            max_fonts=MAX_FONTS_TO_DOWNLOAD,\n",
        "            output_dir=FONTS_OUTPUT_DIR\n",
        "        )\n",
        "    else:\n",
        "        print(\"[INFO] Download skipped. Using existing fonts.\")\n",
        "        download_stats = {'successful': len(existing_fonts), 'downloaded_fonts': []}\n",
        "else:\n",
        "    # No existing fonts, start download\n",
        "    download_stats = download_handwriting_fonts(\n",
        "        max_fonts=MAX_FONTS_TO_DOWNLOAD,\n",
        "        output_dir=FONTS_OUTPUT_DIR\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8CAgSaDo04P",
        "outputId": "8435ad90-5914-4739-b4b8-faf4852a8e8e"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DEPENDENCY INSTALLATION\n",
        "# =============================================================================\n",
        "# This cell installs all necessary libraries for:\n",
        "#   - Font downloading via API (requests, tqdm)\n",
        "#   - Image generation (Pillow, numpy, opencv-python)\n",
        "#   - Processing and augmentation (scipy for advanced operations)\n",
        "\n",
        "# Install requirements for TRDG\n",
        "%pip install -r requirements.txt\n",
        "\n",
        "# Core dependencies\n",
        "%pip install pillow numpy opencv-python requests tqdm matplotlib\n",
        "\n",
        "# Optional dependencies for TRDG (if using legacy generator)\n",
        "%pip install \"arabic-reshaper>=2.1.4\" python-bidi\n",
        "\n",
        "%pip install git+https://github.com/Belval/TextRecognitionDataGenerator.git --no-deps\n",
        "\n",
        "print(\"\\n[OK] All dependencies are installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkfCLYlhoiVd"
      },
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import os\n",
        "import string\n",
        "from pathlib import Path\n",
        "from trdg.generators import GeneratorFromStrings\n",
        "import multiprocessing\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XaepDfzovwJ",
        "outputId": "8e8ad88a-ddd7-4978-83e7-df25ef486b0d"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# GLOBAL CONFIGURATION PARAMETERS\n",
        "# =============================================================================\n",
        "# These parameters control the overall behavior of dataset generation.\n",
        "# Modify them according to your requirements before running generation.\n",
        "\n",
        "# Base number of samples per letter (before applying class balancing multipliers)\n",
        "# Note: This number will be automatically adjusted by the class balancing system\n",
        "BASE_SAMPLES_PER_LETTER = 10000\n",
        "\n",
        "# Output directory for generated dataset\n",
        "OUTPUT_ROOT = \"dataset_handwritten_28x28\"\n",
        "\n",
        "# Directory containing handwritten fonts (.ttf files)\n",
        "FONT_DIR = \"./handwritten_fonts\"\n",
        "\n",
        "# List of characters to generate (uppercase A-Z)\n",
        "LETTERS = list(string.ascii_uppercase)\n",
        "\n",
        "# Enable/disable automatic class balancing\n",
        "USE_CLASS_BALANCING = True\n",
        "\n",
        "# =============================================================================\n",
        "# DISPLAY CONFIGURATION\n",
        "# =============================================================================\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET GENERATOR CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n[GENERAL PARAMETERS]\")\n",
        "print(f\"  - Base samples per letter: {BASE_SAMPLES_PER_LETTER}\")\n",
        "print(f\"  - Output directory: {OUTPUT_ROOT}\")\n",
        "print(f\"  - Font directory: {FONT_DIR}\")\n",
        "print(f\"  - Number of characters: {len(LETTERS)}\")\n",
        "print(f\"  - Class balancing: {'Enabled' if USE_CLASS_BALANCING else 'Disabled'}\")\n",
        "\n",
        "if USE_CLASS_BALANCING:\n",
        "    print(f\"\\n[CLASS BALANCING]\")\n",
        "    print(f\"  Underrepresented classes (x2.5): I, F, G, K, Q, X, Z\")\n",
        "    print(f\"  Overrepresented classes (x0.7): O, S\")\n",
        "\n",
        "    # Calculate estimated total\n",
        "    total_estimated = 0\n",
        "    for letter in LETTERS:\n",
        "        if letter in ['I', 'F', 'G', 'K', 'Q', 'X', 'Z']:\n",
        "            total_estimated += int(BASE_SAMPLES_PER_LETTER * 2.5)\n",
        "        elif letter in ['O', 'S']:\n",
        "            total_estimated += int(BASE_SAMPLES_PER_LETTER * 0.7)\n",
        "        else:\n",
        "            total_estimated += BASE_SAMPLES_PER_LETTER\n",
        "    print(f\"\\n  Estimated total images: {total_estimated:,}\")\n",
        "else:\n",
        "    print(f\"\\n  Total images: {BASE_SAMPLES_PER_LETTER * len(LETTERS):,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtHbFIf10N40"
      },
      "outputs": [],
      "source": [
        "def get_handwritten_fonts(font_dir):\n",
        "    \"\"\"\n",
        "    Load all .ttf font files from the specified directory.\n",
        "\n",
        "    Args:\n",
        "        font_dir (str): Path to directory containing .ttf font files\n",
        "\n",
        "    Returns:\n",
        "        list: List of font file paths\n",
        "    \"\"\"\n",
        "    font_path = Path(font_dir)\n",
        "\n",
        "    if not font_path.exists():\n",
        "        raise FileNotFoundError(f\"Font directory '{font_dir}' does not exist. Please create it and add .ttf files.\")\n",
        "\n",
        "    fonts = list(font_path.glob(\"*.ttf\"))\n",
        "\n",
        "    if not fonts:\n",
        "        raise FileNotFoundError(f\"No .ttf files found in '{font_dir}'. Please add handwritten font files.\")\n",
        "\n",
        "    font_paths = [str(font) for font in fonts]\n",
        "    print(f\"Found {len(font_paths)} handwritten fonts:\")\n",
        "    for font in font_paths:\n",
        "        print(f\"  - {Path(font).name}\")\n",
        "\n",
        "    return font_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWiW8s0g0Q_U"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "===============================================================================\n",
        "MODULE: SYNTHETIC IMAGE GENERATOR FOR OCR (ADVANCED VERSION)\n",
        "===============================================================================\n",
        "This module implements an optimized synthetic image generation system for\n",
        "training CNN models for character recognition (OCR).\n",
        "\n",
        "Key Features:\n",
        "    - Class imbalance handling (underrepresented/overrepresented classes)\n",
        "    - Realistic geometric augmentation (rotation, translation, scale)\n",
        "    - Handwritten stroke simulation (variable thickness, blur, morphology)\n",
        "    - 28x28 grayscale image generation\n",
        "    - Modular architecture with configurable parameters\n",
        "\n",
        "Dependencies:\n",
        "    - PIL (Pillow): Image manipulation and text rendering\n",
        "    - NumPy: Matrix operations and Gaussian noise\n",
        "    - OpenCV (cv2): Morphological operations and filters\n",
        "    - multiprocessing: CPU parallelization\n",
        "\n",
        "Author: Mohamed\n",
        "Date: December 2024\n",
        "Version: 2.0\n",
        "===============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import multiprocessing\n",
        "from multiprocessing import Pool\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
        "\n",
        "# Attempt to import OpenCV (optional but recommended)\n",
        "try:\n",
        "    import cv2\n",
        "    CV2_AVAILABLE = True\n",
        "except ImportError:\n",
        "    CV2_AVAILABLE = False\n",
        "    print(\"[WARNING] OpenCV not available. Morphological operations will be disabled.\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 1: CONFIGURATION AND GLOBAL PARAMETERS\n",
        "# =============================================================================\n",
        "\n",
        "class AugmentationConfig:\n",
        "    \"\"\"\n",
        "    Configuration class centralizing all augmentation parameters.\n",
        "\n",
        "    This class allows easy modification of generation hyperparameters\n",
        "    without changing function code.\n",
        "\n",
        "    Attributes:\n",
        "        IMAGE_SIZE (int): Output image size (28x28 pixels).\n",
        "        BACKGROUND_RANGE (tuple): Light background value range (220-255).\n",
        "        TEXT_COLOR_RANGE (tuple): Dark text value range (0-50).\n",
        "        ROTATION_RANGE (tuple): Rotation range in degrees (-15 to +15).\n",
        "        TRANSLATION_RANGE (tuple): Translation range in pixels (-3 to +3).\n",
        "        SCALE_RANGE (tuple): Relative scale range (0.60 to 0.85).\n",
        "        STROKE_WIDTH_RANGE (tuple): Stroke width range (1 to 4 pixels).\n",
        "        BLUR_RADIUS_RANGE (tuple): Gaussian blur radius range (0.0 to 1.5).\n",
        "        GAUSSIAN_NOISE_STD (float): Gaussian noise standard deviation (0-10).\n",
        "        MORPHOLOGY_KERNEL_SIZE (int): Kernel size for morphological operations.\n",
        "        MORPHOLOGY_PROBABILITY (float): Probability of applying morphological operation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Output image specifications\n",
        "    IMAGE_SIZE: int = 28\n",
        "    BACKGROUND_RANGE: Tuple[int, int] = (220, 255)\n",
        "    TEXT_COLOR_RANGE: Tuple[int, int] = (0, 50)\n",
        "\n",
        "    # Geometric augmentation parameters\n",
        "    ROTATION_RANGE: Tuple[float, float] = (-15.0, 15.0)\n",
        "    TRANSLATION_RANGE: Tuple[int, int] = (-3, 3)\n",
        "    SCALE_RANGE: Tuple[float, float] = (0.60, 0.85)\n",
        "\n",
        "    # Stroke simulation parameters\n",
        "    STROKE_WIDTH_RANGE: Tuple[int, int] = (1, 4)\n",
        "    BLUR_RADIUS_RANGE: Tuple[float, float] = (0.0, 1.5)\n",
        "    GAUSSIAN_NOISE_STD: float = 5.0\n",
        "\n",
        "    # Morphological parameters\n",
        "    MORPHOLOGY_KERNEL_SIZE: int = 2\n",
        "    MORPHOLOGY_PROBABILITY: float = 0.3\n",
        "\n",
        "\n",
        "class ClassBalanceConfig:\n",
        "    \"\"\"\n",
        "    Configuration for class imbalance handling.\n",
        "\n",
        "    This class defines volume multipliers for each character category\n",
        "    to compensate for natural dataset imbalances.\n",
        "\n",
        "    Attributes:\n",
        "        UNDERREPRESENTED_CHARS (list): Underrepresented characters requiring\n",
        "            more samples (I, F, G, K, Q, X, Z).\n",
        "        OVERREPRESENTED_CHARS (list): Overrepresented characters requiring\n",
        "            fewer samples (O, S).\n",
        "        UNDERREPRESENTED_MULTIPLIER (float): Multiplier for rare classes (2.5x).\n",
        "        OVERREPRESENTED_MULTIPLIER (float): Multiplier for frequent classes (0.7x).\n",
        "        DEFAULT_MULTIPLIER (float): Default multiplier (1.0x).\n",
        "    \"\"\"\n",
        "\n",
        "    # Underrepresented characters (need more samples)\n",
        "    UNDERREPRESENTED_CHARS: List[str] = ['I', 'F', 'G', 'K', 'Q', 'X', 'Z']\n",
        "\n",
        "    # Overrepresented characters (need fewer samples)\n",
        "    OVERREPRESENTED_CHARS: List[str] = ['O', 'S']\n",
        "\n",
        "    # Volume multipliers\n",
        "    UNDERREPRESENTED_MULTIPLIER: float = 2.5\n",
        "    OVERREPRESENTED_MULTIPLIER: float = 0.7\n",
        "    DEFAULT_MULTIPLIER: float = 1.0\n",
        "\n",
        "    @classmethod\n",
        "    def get_multiplier(cls, letter: str) -> float:\n",
        "        \"\"\"\n",
        "        Return the volume multiplier for a given character.\n",
        "\n",
        "        Args:\n",
        "            letter (str): The character to get the multiplier for.\n",
        "\n",
        "        Returns:\n",
        "            float: The volume multiplier to apply.\n",
        "        \"\"\"\n",
        "        if letter in cls.UNDERREPRESENTED_CHARS:\n",
        "            return cls.UNDERREPRESENTED_MULTIPLIER\n",
        "        elif letter in cls.OVERREPRESENTED_CHARS:\n",
        "            return cls.OVERREPRESENTED_MULTIPLIER\n",
        "        else:\n",
        "            return cls.DEFAULT_MULTIPLIER\n",
        "\n",
        "    @classmethod\n",
        "    def get_samples_count(cls, letter: str, base_samples: int) -> int:\n",
        "        \"\"\"\n",
        "        Calculate the number of samples to generate for a character.\n",
        "\n",
        "        Args:\n",
        "            letter (str): The target character.\n",
        "            base_samples (int): Base number of samples.\n",
        "\n",
        "        Returns:\n",
        "            int: Adjusted number of samples to generate.\n",
        "        \"\"\"\n",
        "        multiplier = cls.get_multiplier(letter)\n",
        "        return int(base_samples * multiplier)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 2: IMAGE AUGMENTATION FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def create_background(size: int, config: AugmentationConfig = AugmentationConfig) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Create a background image with random light pixel values.\n",
        "\n",
        "    This function generates a non-uniform background to simulate natural\n",
        "    variations in paper or writing surfaces.\n",
        "\n",
        "    Args:\n",
        "        size (int): Square image size in pixels.\n",
        "        config (AugmentationConfig): Parameter configuration.\n",
        "\n",
        "    Returns:\n",
        "        Image.Image: PIL image in 'L' mode (grayscale) with light background.\n",
        "    \"\"\"\n",
        "    bg_min, bg_max = config.BACKGROUND_RANGE\n",
        "\n",
        "    # Generate random value array for background\n",
        "    background_array = np.random.randint(\n",
        "        low=bg_min,\n",
        "        high=bg_max + 1,\n",
        "        size=(size, size),\n",
        "        dtype=np.uint8\n",
        "    )\n",
        "\n",
        "    return Image.fromarray(background_array, mode='L')\n",
        "\n",
        "\n",
        "def select_text_color(config: AugmentationConfig = AugmentationConfig) -> int:\n",
        "    \"\"\"\n",
        "    Select a random dark text color.\n",
        "\n",
        "    Args:\n",
        "        config (AugmentationConfig): Parameter configuration.\n",
        "\n",
        "    Returns:\n",
        "        int: Pixel value for text (0-50).\n",
        "    \"\"\"\n",
        "    return random.randint(config.TEXT_COLOR_RANGE[0], config.TEXT_COLOR_RANGE[1])\n",
        "\n",
        "\n",
        "def calculate_font_size(\n",
        "    target_scale: float,\n",
        "    image_size: int,\n",
        "    font_path: str,\n",
        "    character: str\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Calculate optimal font size to achieve target scale.\n",
        "\n",
        "    This function performs an iterative search to find the font size\n",
        "    that allows the character to occupy the desired percentage of\n",
        "    the image area.\n",
        "\n",
        "    Args:\n",
        "        target_scale (float): Percentage of image the character should occupy (0.6-0.85).\n",
        "        image_size (int): Image size in pixels.\n",
        "        font_path (str): Path to TTF font file.\n",
        "        character (str): The character to render.\n",
        "\n",
        "    Returns:\n",
        "        int: Calculated font size.\n",
        "    \"\"\"\n",
        "    target_size = int(image_size * target_scale)\n",
        "\n",
        "    # Binary search to find appropriate font size\n",
        "    low, high = 8, 100\n",
        "    best_size = 20\n",
        "\n",
        "    while low <= high:\n",
        "        mid = (low + high) // 2\n",
        "        try:\n",
        "            font = ImageFont.truetype(font_path, mid)\n",
        "            bbox = font.getbbox(character)\n",
        "            char_width = bbox[2] - bbox[0]\n",
        "            char_height = bbox[3] - bbox[1]\n",
        "            max_dim = max(char_width, char_height)\n",
        "\n",
        "            if max_dim < target_size:\n",
        "                best_size = mid\n",
        "                low = mid + 1\n",
        "            else:\n",
        "                high = mid - 1\n",
        "        except Exception:\n",
        "            # On error, use default size\n",
        "            break\n",
        "\n",
        "    return best_size\n",
        "\n",
        "\n",
        "def apply_rotation(\n",
        "    image: Image.Image,\n",
        "    angle: float,\n",
        "    fill_color: int\n",
        ") -> Image.Image:\n",
        "    \"\"\"\n",
        "    Apply rotation to the image with background fill.\n",
        "\n",
        "    Args:\n",
        "        image (Image.Image): Source image.\n",
        "        angle (float): Rotation angle in degrees.\n",
        "        fill_color (int): Fill color for empty regions.\n",
        "\n",
        "    Returns:\n",
        "        Image.Image: Image after rotation.\n",
        "    \"\"\"\n",
        "    return image.rotate(\n",
        "        angle,\n",
        "        resample=Image.BICUBIC,\n",
        "        expand=False,\n",
        "        fillcolor=fill_color\n",
        "    )\n",
        "\n",
        "\n",
        "def apply_gaussian_blur(\n",
        "    image: Image.Image,\n",
        "    radius: float\n",
        ") -> Image.Image:\n",
        "    \"\"\"\n",
        "    Apply Gaussian blur to the image.\n",
        "\n",
        "    Gaussian blur helps reduce digital artifacts and simulate\n",
        "    more natural handwritten character rendering.\n",
        "\n",
        "    Args:\n",
        "        image (Image.Image): Source image.\n",
        "        radius (float): Gaussian blur radius.\n",
        "\n",
        "    Returns:\n",
        "        Image.Image: Image with blur applied.\n",
        "    \"\"\"\n",
        "    if radius > 0:\n",
        "        return image.filter(ImageFilter.GaussianBlur(radius=radius))\n",
        "    return image\n",
        "\n",
        "\n",
        "def add_gaussian_noise(\n",
        "    image: Image.Image,\n",
        "    std_dev: float\n",
        ") -> Image.Image:\n",
        "    \"\"\"\n",
        "    Add Gaussian noise to the image.\n",
        "\n",
        "    Gaussian noise simulates natural imperfections and improves\n",
        "    robustness of models trained on this data.\n",
        "\n",
        "    Args:\n",
        "        image (Image.Image): Source image.\n",
        "        std_dev (float): Gaussian noise standard deviation.\n",
        "\n",
        "    Returns:\n",
        "        Image.Image: Image with added noise.\n",
        "    \"\"\"\n",
        "    if std_dev <= 0:\n",
        "        return image\n",
        "\n",
        "    img_array = np.array(image, dtype=np.float32)\n",
        "    noise = np.random.normal(0, std_dev, img_array.shape)\n",
        "    noisy_array = np.clip(img_array + noise, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return Image.fromarray(noisy_array, mode='L')\n",
        "\n",
        "\n",
        "def apply_morphological_operation(\n",
        "    image: Image.Image,\n",
        "    kernel_size: int,\n",
        "    operation: str = 'random'\n",
        ") -> Image.Image:\n",
        "    \"\"\"\n",
        "    Apply morphological operation to the image.\n",
        "\n",
        "    Morphological operations (erosion, dilation) allow slight deformation\n",
        "    of character structure to simulate natural handwriting variations.\n",
        "\n",
        "    Args:\n",
        "        image (Image.Image): Source image.\n",
        "        kernel_size (int): Structuring element size.\n",
        "        operation (str): Operation type ('erode', 'dilate', 'random').\n",
        "\n",
        "    Returns:\n",
        "        Image.Image: Image after morphological operation.\n",
        "\n",
        "    Note:\n",
        "        This function requires OpenCV. If OpenCV is not available,\n",
        "        the image is returned without modification.\n",
        "    \"\"\"\n",
        "    if not CV2_AVAILABLE:\n",
        "        return image\n",
        "\n",
        "    img_array = np.array(image)\n",
        "\n",
        "    # Create structuring element\n",
        "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
        "\n",
        "    # Select operation\n",
        "    if operation == 'random':\n",
        "        operation = random.choice(['erode', 'dilate'])\n",
        "\n",
        "    # Invert image for morphological operations\n",
        "    # (text must be white on black background for standard operations)\n",
        "    inverted = 255 - img_array\n",
        "\n",
        "    if operation == 'erode':\n",
        "        result = cv2.erode(inverted, kernel, iterations=1)\n",
        "    elif operation == 'dilate':\n",
        "        result = cv2.dilate(inverted, kernel, iterations=1)\n",
        "    else:\n",
        "        result = inverted\n",
        "\n",
        "    # Re-invert to return to original format\n",
        "    final = 255 - result\n",
        "\n",
        "    return Image.fromarray(final, mode='L')\n",
        "\n",
        "\n",
        "def simulate_stroke_width(\n",
        "    draw: ImageDraw.Draw,\n",
        "    position: Tuple[int, int],\n",
        "    character: str,\n",
        "    font: ImageFont.FreeTypeFont,\n",
        "    color: int,\n",
        "    stroke_width: int\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Draw a character with variable stroke width.\n",
        "\n",
        "    To simulate thick strokes (marker-style), the character is\n",
        "    drawn multiple times with slight offsets.\n",
        "\n",
        "    Args:\n",
        "        draw (ImageDraw.Draw): PIL drawing object.\n",
        "        position (tuple): Position (x, y) of the character.\n",
        "        character (str): The character to draw.\n",
        "        font (ImageFont.FreeTypeFont): Font to use.\n",
        "        color (int): Text color.\n",
        "        stroke_width (int): Stroke width (1-4).\n",
        "    \"\"\"\n",
        "    x, y = position\n",
        "\n",
        "    if stroke_width <= 1:\n",
        "        # Thin stroke: simple drawing\n",
        "        draw.text((x, y), character, font=font, fill=color)\n",
        "    else:\n",
        "        # Thick stroke: multiple drawings with offsets\n",
        "        offsets = []\n",
        "        for dx in range(-stroke_width // 2, stroke_width // 2 + 1):\n",
        "            for dy in range(-stroke_width // 2, stroke_width // 2 + 1):\n",
        "                if dx * dx + dy * dy <= (stroke_width // 2) ** 2:\n",
        "                    offsets.append((dx, dy))\n",
        "\n",
        "        for dx, dy in offsets:\n",
        "            draw.text((x + dx, y + dy), character, font=font, fill=color)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 3: MAIN IMAGE GENERATION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def generate_augmented_character_image(\n",
        "    character: str,\n",
        "    font_path: str,\n",
        "    config: AugmentationConfig = AugmentationConfig\n",
        ") -> Image.Image:\n",
        "    \"\"\"\n",
        "    Generate an augmented character image with all transformations.\n",
        "\n",
        "    This main function orchestrates the entire generation pipeline:\n",
        "    1. Random background creation\n",
        "    2. Scale and font size calculation\n",
        "    3. Character rendering with variable thickness\n",
        "    4. Geometric transformation application\n",
        "    5. Noise and blur application\n",
        "    6. Optional morphological operations\n",
        "\n",
        "    Args:\n",
        "        character (str): The character to generate.\n",
        "        font_path (str): Path to TTF font file.\n",
        "        config (AugmentationConfig): Augmentation parameter configuration.\n",
        "\n",
        "    Returns:\n",
        "        Image.Image: 28x28 grayscale image of augmented character.\n",
        "    \"\"\"\n",
        "    size = config.IMAGE_SIZE\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 1: Create background with random light values\n",
        "    # -------------------------------------------------------------------------\n",
        "    background = create_background(size, config)\n",
        "    background_value = int(np.mean(np.array(background)))\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 2: Select random parameters\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Character scale (60% to 85% of image)\n",
        "    target_scale = random.uniform(config.SCALE_RANGE[0], config.SCALE_RANGE[1])\n",
        "\n",
        "    # Rotation (-15 to +15 degrees)\n",
        "    rotation_angle = random.uniform(config.ROTATION_RANGE[0], config.ROTATION_RANGE[1])\n",
        "\n",
        "    # Translation (center offset)\n",
        "    trans_x = random.randint(config.TRANSLATION_RANGE[0], config.TRANSLATION_RANGE[1])\n",
        "    trans_y = random.randint(config.TRANSLATION_RANGE[0], config.TRANSLATION_RANGE[1])\n",
        "\n",
        "    # Stroke width\n",
        "    stroke_width = random.randint(config.STROKE_WIDTH_RANGE[0], config.STROKE_WIDTH_RANGE[1])\n",
        "\n",
        "    # Gaussian blur\n",
        "    blur_radius = random.uniform(config.BLUR_RADIUS_RANGE[0], config.BLUR_RADIUS_RANGE[1])\n",
        "\n",
        "    # Text color (dark)\n",
        "    text_color = select_text_color(config)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 3: Calculate optimal font size\n",
        "    # -------------------------------------------------------------------------\n",
        "    font_size = calculate_font_size(target_scale, size, font_path, character)\n",
        "\n",
        "    try:\n",
        "        font = ImageFont.truetype(font_path, font_size)\n",
        "    except Exception as e:\n",
        "        # Fallback to default font on error\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 4: Calculate centered position with translation\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Get character dimensions\n",
        "    bbox = font.getbbox(character)\n",
        "    char_width = bbox[2] - bbox[0]\n",
        "    char_height = bbox[3] - bbox[1]\n",
        "\n",
        "    # Centered position\n",
        "    center_x = (size - char_width) // 2\n",
        "    center_y = (size - char_height) // 2\n",
        "\n",
        "    # Apply translation (offset from perfect center)\n",
        "    pos_x = center_x + trans_x - bbox[0]\n",
        "    pos_y = center_y + trans_y - bbox[1]\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 5: Draw character with variable stroke width\n",
        "    # -------------------------------------------------------------------------\n",
        "    draw = ImageDraw.Draw(background)\n",
        "    simulate_stroke_width(draw, (pos_x, pos_y), character, font, text_color, stroke_width)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 6: Apply rotation\n",
        "    # -------------------------------------------------------------------------\n",
        "    rotated_image = apply_rotation(background, rotation_angle, background_value)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 7: Apply Gaussian blur\n",
        "    # -------------------------------------------------------------------------\n",
        "    blurred_image = apply_gaussian_blur(rotated_image, blur_radius)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 8: Add Gaussian noise\n",
        "    # -------------------------------------------------------------------------\n",
        "    noisy_image = add_gaussian_noise(blurred_image, config.GAUSSIAN_NOISE_STD)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # STEP 9: Morphological operations (probabilistic)\n",
        "    # -------------------------------------------------------------------------\n",
        "    if random.random() < config.MORPHOLOGY_PROBABILITY:\n",
        "        final_image = apply_morphological_operation(\n",
        "            noisy_image,\n",
        "            config.MORPHOLOGY_KERNEL_SIZE\n",
        "        )\n",
        "    else:\n",
        "        final_image = noisy_image\n",
        "\n",
        "    return final_image\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 4: DATASET GENERATION FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def generate_single_image_worker(args: Tuple) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Worker function for parallel generation of a single image.\n",
        "\n",
        "    This function is designed for use with multiprocessing.Pool.\n",
        "    It generates an augmented image and saves it to disk.\n",
        "\n",
        "    Args:\n",
        "        args (tuple): Tuple containing:\n",
        "            - letter (str): The character to generate\n",
        "            - index (int): Image index in sequence\n",
        "            - font_paths (list): List of paths to fonts\n",
        "            - output_dir (str): Output directory\n",
        "            - total_samples (int): Total number of samples for progress tracking\n",
        "\n",
        "    Returns:\n",
        "        Optional[str]: Progress message or None.\n",
        "    \"\"\"\n",
        "    letter, index, font_paths, output_dir, total_samples = args\n",
        "\n",
        "    # Cyclic font selection\n",
        "    selected_font = font_paths[index % len(font_paths)]\n",
        "\n",
        "    # Generate augmented image\n",
        "    image = generate_augmented_character_image(\n",
        "        character=letter,\n",
        "        font_path=selected_font,\n",
        "        config=AugmentationConfig\n",
        "    )\n",
        "\n",
        "    # Save image\n",
        "    filename = f\"{letter}_{index + 1:05d}.png\"\n",
        "    filepath = Path(output_dir) / filename\n",
        "    image.save(filepath, format='PNG')\n",
        "\n",
        "    # Progress message every 50 samples\n",
        "    if (index + 1) % 50 == 0:\n",
        "        return f\"    - Progress: {index + 1}/{total_samples} images generated\"\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def generate_handwritten_dataset(\n",
        "    letters: List[str],\n",
        "    base_samples_per_letter: int,\n",
        "    output_root: str,\n",
        "    font_paths: List[str],\n",
        "    use_class_balancing: bool = True\n",
        ") -> Dict[str, int]:\n",
        "    \"\"\"\n",
        "    Generate a complete synthetic handwritten character dataset.\n",
        "\n",
        "    This main function manages the entire generation process:\n",
        "    - Class balancing application\n",
        "    - Multi-core CPU parallelization\n",
        "    - Progress tracking\n",
        "    - Organized saving by subdirectories\n",
        "\n",
        "    Args:\n",
        "        letters (List[str]): List of characters to generate.\n",
        "        base_samples_per_letter (int): Base number of samples per character.\n",
        "        output_root (str): Root output directory.\n",
        "        font_paths (List[str]): List of paths to TTF fonts.\n",
        "        use_class_balancing (bool): Enable class balancing.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, int]: Dictionary {letter: number_images_generated}.\n",
        "\n",
        "    Example:\n",
        "        >>> letters = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "        >>> fonts = get_handwritten_fonts('./fonts')\n",
        "        >>> stats = generate_handwritten_dataset(letters, 1000, './output', fonts)\n",
        "        >>> print(f\"Total: {sum(stats.values())} images\")\n",
        "    \"\"\"\n",
        "    # -------------------------------------------------------------------------\n",
        "    # MULTIPROCESSING CONFIGURATION\n",
        "    # -------------------------------------------------------------------------\n",
        "    num_cores = multiprocessing.cpu_count()\n",
        "    num_processes = max(1, num_cores - 1) if num_cores > 2 else num_cores\n",
        "\n",
        "    # Create root directory\n",
        "    Path(output_root).mkdir(exist_ok=True)\n",
        "\n",
        "    # Generation statistics\n",
        "    generation_stats: Dict[str, int] = {}\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # DISPLAY CONFIGURATION\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"OCR DATASET GENERATOR - ADVANCED VERSION\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\n[SYSTEM CONFIGURATION]\")\n",
        "    print(f\"  - CPU cores detected: {num_cores}\")\n",
        "    print(f\"  - Parallel processes: {num_processes}\")\n",
        "    print(f\"  - Available fonts: {len(font_paths)}\")\n",
        "\n",
        "    print(f\"\\n[IMAGE PARAMETERS]\")\n",
        "    print(f\"  - Output size: {AugmentationConfig.IMAGE_SIZE}x{AugmentationConfig.IMAGE_SIZE} pixels\")\n",
        "    print(f\"  - Format: Grayscale (mode 'L')\")\n",
        "    print(f\"  - Background: {AugmentationConfig.BACKGROUND_RANGE[0]}-{AugmentationConfig.BACKGROUND_RANGE[1]}\")\n",
        "    print(f\"  - Text: {AugmentationConfig.TEXT_COLOR_RANGE[0]}-{AugmentationConfig.TEXT_COLOR_RANGE[1]}\")\n",
        "\n",
        "    print(f\"\\n[GEOMETRIC AUGMENTATION]\")\n",
        "    print(f\"  - Rotation: {AugmentationConfig.ROTATION_RANGE[0]} to {AugmentationConfig.ROTATION_RANGE[1]} degrees\")\n",
        "    print(f\"  - Translation: {AugmentationConfig.TRANSLATION_RANGE[0]} to {AugmentationConfig.TRANSLATION_RANGE[1]} pixels\")\n",
        "    print(f\"  - Scale: {AugmentationConfig.SCALE_RANGE[0]*100:.0f}% to {AugmentationConfig.SCALE_RANGE[1]*100:.0f}%\")\n",
        "\n",
        "    print(f\"\\n[STROKE SIMULATION]\")\n",
        "    print(f\"  - Thickness: {AugmentationConfig.STROKE_WIDTH_RANGE[0]} to {AugmentationConfig.STROKE_WIDTH_RANGE[1]} pixels\")\n",
        "    print(f\"  - Gaussian blur: {AugmentationConfig.BLUR_RADIUS_RANGE[0]} to {AugmentationConfig.BLUR_RADIUS_RANGE[1]}\")\n",
        "    print(f\"  - Gaussian noise: sigma={AugmentationConfig.GAUSSIAN_NOISE_STD}\")\n",
        "    print(f\"  - Morphological operations: {'Enabled' if CV2_AVAILABLE else 'Disabled (OpenCV missing)'}\")\n",
        "\n",
        "    if use_class_balancing:\n",
        "        print(f\"\\n[CLASS BALANCING]\")\n",
        "        print(f\"  - Underrepresented ({ClassBalanceConfig.UNDERREPRESENTED_MULTIPLIER}x): {ClassBalanceConfig.UNDERREPRESENTED_CHARS}\")\n",
        "        print(f\"  - Overrepresented ({ClassBalanceConfig.OVERREPRESENTED_MULTIPLIER}x): {ClassBalanceConfig.OVERREPRESENTED_CHARS}\")\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # GENERATION LOOP BY LETTER\n",
        "    # -------------------------------------------------------------------------\n",
        "    total_images = 0\n",
        "\n",
        "    for letter in letters:\n",
        "        # Calculate number of samples with balancing\n",
        "        if use_class_balancing:\n",
        "            samples_count = ClassBalanceConfig.get_samples_count(letter, base_samples_per_letter)\n",
        "            multiplier = ClassBalanceConfig.get_multiplier(letter)\n",
        "            balance_info = f\" (x{multiplier})\"\n",
        "        else:\n",
        "            samples_count = base_samples_per_letter\n",
        "            balance_info = \"\"\n",
        "\n",
        "        # Create subdirectory\n",
        "        letter_dir = Path(output_root) / letter\n",
        "        letter_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        print(f\"\\n[GENERATION] Letter '{letter}'{balance_info}: {samples_count} images\")\n",
        "\n",
        "        # Prepare arguments for multiprocessing\n",
        "        args_list = [\n",
        "            (letter, i, font_paths, str(letter_dir), samples_count)\n",
        "            for i in range(samples_count)\n",
        "        ]\n",
        "\n",
        "        # Parallel generation\n",
        "        with Pool(processes=num_processes) as pool:\n",
        "            results = pool.map(generate_single_image_worker, args_list)\n",
        "\n",
        "            # Display progress messages\n",
        "            for result in results:\n",
        "                if result:\n",
        "                    print(result)\n",
        "\n",
        "        # Update statistics\n",
        "        generation_stats[letter] = samples_count\n",
        "        total_images += samples_count\n",
        "\n",
        "        print(f\"  [OK] Letter '{letter}' completed: {samples_count} images in {letter_dir}\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # FINAL SUMMARY\n",
        "    # -------------------------------------------------------------------------\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"GENERATION COMPLETED\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\n[FINAL STATISTICS]\")\n",
        "    print(f\"  - Total images generated: {total_images}\")\n",
        "    print(f\"  - Number of classes: {len(letters)}\")\n",
        "    print(f\"  - Location: {Path(output_root).absolute()}\")\n",
        "\n",
        "    if use_class_balancing:\n",
        "        print(f\"\\n[CLASS DISTRIBUTION]\")\n",
        "        for letter, count in sorted(generation_stats.items()):\n",
        "            bar_length = int(count / max(generation_stats.values()) * 30)\n",
        "            bar = \"#\" * bar_length\n",
        "            print(f\"  {letter}: {count:5d} |{bar}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "    return generation_stats\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# SECTION 5: UTILITY FUNCTION FOR VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "def preview_augmentation(\n",
        "    character: str,\n",
        "    font_path: str,\n",
        "    num_samples: int = 10\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Generate and display a preview of several augmented variants.\n",
        "\n",
        "    Utility function to visualize the effect of augmentations on a given\n",
        "    character before launching a complete generation.\n",
        "\n",
        "    Args:\n",
        "        character (str): The character to visualize.\n",
        "        font_path (str): Path to the font to use.\n",
        "        num_samples (int): Number of variants to generate.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "        fig.suptitle(f\"Augmentation Preview for '{character}'\", fontsize=14)\n",
        "\n",
        "        for idx, ax in enumerate(axes.flat):\n",
        "            if idx < num_samples:\n",
        "                img = generate_augmented_character_image(character, font_path)\n",
        "                ax.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
        "                ax.set_title(f\"Variant {idx + 1}\", fontsize=10)\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"[ERROR] matplotlib is not installed. Install it with: pip install matplotlib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7FFH22s55ZT"
      },
      "source": [
        "## Multiprocessing Optimization and Augmentation Pipeline\n",
        "\n",
        "**Synthetic Image Generation System Architecture:**\n",
        "\n",
        "The image generation pipeline includes the following steps for each character:\n",
        "\n",
        "1. **Background Creation**: Random pixel values between 220-255 (light background)\n",
        "2. **Parameter Selection**: Scale, rotation, translation, stroke thickness\n",
        "3. **Character Rendering**: Drawing with variable thickness (1-4 pixels)\n",
        "4. **Rotation**: Apply random rotation (-15 to +15 degrees)\n",
        "5. **Gaussian Blur**: Edge softening (radius 0-1.5)\n",
        "6. **Gaussian Noise**: Add noise for robustness (sigma=5)\n",
        "7. **Morphological Operations**: Random erosion/dilation (30% probability)\n",
        "\n",
        "**Class Imbalance Management:**\n",
        "\n",
        "| Category | Characters | Multiplier |\n",
        "|----------|------------|------------|\n",
        "| Underrepresented | I, F, G, K, Q, X, Z | x2.5 |\n",
        "| Standard | A, B, C, D, E, H, J, L, M, N, P, R, T, U, V, W, Y | x1.0 |\n",
        "| Overrepresented | O, S | x0.7 |\n",
        "\n",
        "**Multiprocessing Performance:**\n",
        "\n",
        "- Free Colab (2 cores): 2x faster\n",
        "- Colab Pro (4+ cores): 3-4x faster\n",
        "- Local machine (8+ cores): 6-8x faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BFyfr0tMehqS",
        "outputId": "c6680f4c-f7ee-4eb0-8aa0-fb54250c55a3"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# AUGMENTATION PREVIEW (OPTIONAL)\n",
        "# =============================================================================\n",
        "# Execute this cell to visualize the effect of augmentations on a character\n",
        "# before launching the complete dataset generation.\n",
        "# This allows visual validation that parameters are correct.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_augmentation_samples(\n",
        "    characters: list = ['A', 'B', 'I', 'O', 'Q'],\n",
        "    samples_per_char: int = 5\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Display a preview grid of augmentation variations.\n",
        "\n",
        "    Args:\n",
        "        characters (list): List of characters to visualize.\n",
        "        samples_per_char (int): Number of variants per character.\n",
        "    \"\"\"\n",
        "    # Load available fonts\n",
        "    try:\n",
        "        font_paths = get_handwritten_fonts(FONT_DIR)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"[ERROR] {e}\")\n",
        "        return\n",
        "\n",
        "    num_chars = len(characters)\n",
        "    fig, axes = plt.subplots(num_chars, samples_per_char, figsize=(12, 2.5 * num_chars))\n",
        "    fig.suptitle(\"Augmentation Preview - 28x28 Images\", fontsize=14, fontweight='bold')\n",
        "\n",
        "    for row, char in enumerate(characters):\n",
        "        for col in range(samples_per_char):\n",
        "            # Random font selection\n",
        "            font_path = random.choice(font_paths)\n",
        "\n",
        "            # Generate augmented image\n",
        "            img = generate_augmented_character_image(char, font_path)\n",
        "\n",
        "            # Display\n",
        "            ax = axes[row, col] if num_chars > 1 else axes[col]\n",
        "            ax.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
        "\n",
        "            if col == 0:\n",
        "                ax.set_ylabel(f\"'{char}'\", fontsize=12, fontweight='bold')\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.92)\n",
        "    plt.show()\n",
        "\n",
        "    # Image statistics\n",
        "    print(\"\\n[IMAGE STATISTICS]\")\n",
        "    sample_img = generate_augmented_character_image('A', font_paths[0])\n",
        "    img_array = np.array(sample_img)\n",
        "    print(f\"  - Size: {sample_img.size}\")\n",
        "    print(f\"  - Mode: {sample_img.mode}\")\n",
        "    print(f\"  - Mean pixel value: {img_array.mean():.2f}\")\n",
        "    print(f\"  - Normalized mean [0-1]: {img_array.mean() / 255:.3f}\")\n",
        "    print(f\"  - Standard deviation: {img_array.std():.2f}\")\n",
        "\n",
        "\n",
        "# Execute preview\n",
        "print(\"[PREVIEW] Generating augmentation samples...\")\n",
        "visualize_augmentation_samples(\n",
        "    characters=['A', 'I', 'O', 'Q', 'Z'],  # Mix of different characters\n",
        "    samples_per_char=6\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoCUugr10Wv0",
        "outputId": "e3b1847e-8983-4e4e-dabb-abffceb66f3c"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# EXECUTE DATASET GENERATION\n",
        "# =============================================================================\n",
        "# This cell launches the complete dataset generation process.\n",
        "# Ensure that:\n",
        "#   1. Fonts are present in the FONT_DIR directory\n",
        "#   2. Configuration parameters are correctly defined\n",
        "#   3. You have sufficient disk space available\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # ---------------------------------------------------------------------\n",
        "        # STEP 1: Load handwritten fonts\n",
        "        # ---------------------------------------------------------------------\n",
        "        print(\"[INITIALIZATION] Loading handwritten fonts...\")\n",
        "        font_paths = get_handwritten_fonts(FONT_DIR)\n",
        "\n",
        "        if len(font_paths) == 0:\n",
        "            raise FileNotFoundError(\n",
        "                f\"No .ttf fonts found in '{FONT_DIR}'. \"\n",
        "                \"Please add handwritten fonts.\"\n",
        "            )\n",
        "\n",
        "        # ---------------------------------------------------------------------\n",
        "        # STEP 2: Generate complete dataset\n",
        "        # ---------------------------------------------------------------------\n",
        "        print(\"\\n[START] Launching generation...\")\n",
        "\n",
        "        generation_stats = generate_handwritten_dataset(\n",
        "            letters=LETTERS,\n",
        "            base_samples_per_letter=BASE_SAMPLES_PER_LETTER,\n",
        "            output_root=OUTPUT_ROOT,\n",
        "            font_paths=font_paths,\n",
        "            use_class_balancing=USE_CLASS_BALANCING\n",
        "        )\n",
        "\n",
        "        # ---------------------------------------------------------------------\n",
        "        # STEP 3: Save statistics\n",
        "        # ---------------------------------------------------------------------\n",
        "        print(\"\\n[STATISTICS] Saving generation report...\")\n",
        "\n",
        "        stats_file = Path(OUTPUT_ROOT) / \"generation_stats.txt\"\n",
        "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"DATASET GENERATION REPORT\\n\")\n",
        "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "            f.write(f\"Generation date: {__import__('datetime').datetime.now()}\\n\")\n",
        "            f.write(f\"Class balancing: {'Enabled' if USE_CLASS_BALANCING else 'Disabled'}\\n\\n\")\n",
        "            f.write(\"Distribution by class:\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            for letter, count in sorted(generation_stats.items()):\n",
        "                f.write(f\"  {letter}: {count}\\n\")\n",
        "            f.write(\"-\" * 30 + \"\\n\")\n",
        "            f.write(f\"  TOTAL: {sum(generation_stats.values())}\\n\")\n",
        "\n",
        "        print(f\"  Report saved: {stats_file}\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"\\n[ERROR] {e}\")\n",
        "        print(\"\\nSolution: Create the directory and add handwritten .ttf fonts\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n[UNEXPECTED ERROR] {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0yv9qqh8cGg"
      },
      "source": [
        "##  Verify Font Distribution\n",
        "\n",
        "After generation, execute this cell to verify that all fonts have been used equitably:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uPeVF2Q8eNg",
        "outputId": "e1293489-017a-4648-cb62-2e8b0d54a76f"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FONT DISTRIBUTION VERIFICATION\n",
        "# =============================================================================\n",
        "# This function verifies that all fonts are used equitably during\n",
        "# dataset generation.\n",
        "\n",
        "def verify_font_distribution(samples_per_letter: int, num_fonts: int) -> None:\n",
        "    \"\"\"\n",
        "    Verify that all fonts are used equitably.\n",
        "\n",
        "    With cyclic rotation (font_paths[i % len(font_paths)]):\n",
        "    If you have 5 fonts and 100 samples:\n",
        "        - Font 0: samples 0, 5, 10, 15, ... (20 times)\n",
        "        - Font 1: samples 1, 6, 11, 16, ... (20 times)\n",
        "        - etc.\n",
        "\n",
        "    Args:\n",
        "        samples_per_letter (int): Number of samples per letter.\n",
        "        num_fonts (int): Number of available fonts.\n",
        "    \"\"\"\n",
        "    from collections import Counter\n",
        "\n",
        "    # Simulate distribution\n",
        "    font_usage = Counter()\n",
        "    for i in range(samples_per_letter):\n",
        "        font_index = i % num_fonts\n",
        "        font_usage[f\"Font {font_index}\"] += 1\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"FONT DISTRIBUTION (PREDICTION)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for font, count in sorted(font_usage.items()):\n",
        "        percentage = (count / samples_per_letter) * 100\n",
        "        bar_length = int(percentage / 2)\n",
        "        bar = \"#\" * bar_length\n",
        "        print(f\"  {font}: {count:5d} samples ({percentage:5.1f}%) |{bar}\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"[OK] All fonts are used equitably.\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# EXECUTE VERIFICATION\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Check if necessary variables are defined\n",
        "if 'BASE_SAMPLES_PER_LETTER' in dir() and 'font_paths' in globals():\n",
        "    verify_font_distribution(BASE_SAMPLES_PER_LETTER, len(font_paths))\n",
        "elif 'BASE_SAMPLES_PER_LETTER' in dir():\n",
        "    # Load fonts if not loaded\n",
        "    try:\n",
        "        font_paths = get_handwritten_fonts(FONT_DIR)\n",
        "        verify_font_distribution(BASE_SAMPLES_PER_LETTER, len(font_paths))\n",
        "    except Exception as e:\n",
        "        print(f\"[WARNING] Unable to load fonts: {e}\")\n",
        "else:\n",
        "    print(\"[INFO] Execute configuration cells first to define parameters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G51qUCj8HPiT"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5D8Dg3HH2Ue",
        "outputId": "6e3bc60a-36b4-4e6c-8823-5fd3a783b35c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to your generated data folder\n",
        "OUTPUT_ROOT = \"dataset_handwritten_28x28\"\n",
        "\n",
        "# Recursive count of all files\n",
        "total_files = sum([len(files) for r, d, files in os.walk(OUTPUT_ROOT)])\n",
        "\n",
        "print(f\" Total number of files found: {total_files}\")\n",
        "# Verify this number matches 26 * SAMPLES_PER_LETTER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmyHO46tHTMM",
        "outputId": "27958d6a-0253-48d3-f6e2-cee4702e544e"
      },
      "outputs": [],
      "source": [
        "# Create ZIP archive on local Colab disk (fast)\n",
        "# Syntax: zip -r -q [output_archive_name] [source_folder]\n",
        "!zip -r -q dataset_complet_v2.zip dataset_handwritten_28x28\n",
        "\n",
        "print(\" Compression completed. The archive 'dataset_complet_v2.zip' is ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlIiFfNK2ngU"
      },
      "source": [
        "---\n",
        "\n",
        "##  Handwritten Character Simulation: Technical Specification\n",
        "\n",
        "### TRDG Generator Parameters for Handwriting Simulation:\n",
        "\n",
        "#### 1. **Skewing (Slant Effect)**\n",
        "```python\n",
        "skewing_angle=10          # Maximum skew angle in degrees (10)\n",
        "random_skew=True          # Randomizes skew for each image\n",
        "```\n",
        "- **Purpose**: Simulates natural handwriting slant/tilt\n",
        "- **Effect**: Each letter is randomly tilted left or right (mimicking individual writing styles)\n",
        "- **Range**: Angle randomly chosen between -10 to +10\n",
        "\n",
        "#### 2. **Distortion (Natural Hand Movement)**\n",
        "```python\n",
        "distorsion_type=2         # Type 2 = Sine wave distortion\n",
        "distorsion_orientation=2  # 2 = Random (horizontal, vertical, or both)\n",
        "```\n",
        "- **Purpose**: Mimics natural irregularity and waviness of human handwriting\n",
        "- **Distortion Types**:\n",
        "  - `0`: No distortion\n",
        "  - `1`: Simple distortion\n",
        "  - `2`: Sine wave distortion (optimal for handwriting)\n",
        "  - `3`: Cosine wave distortion\n",
        "- **Effect**: Creates wavy, non-linear characters that appear hand-drawn rather than printed\n",
        "\n",
        "#### 3. **Blur (Ink Bleeding Effect)**\n",
        "```python\n",
        "blur=2                    # Blur intensity (0-3)\n",
        "random_blur=True          # Randomizes blur for each image\n",
        "```\n",
        "- **Purpose**: Simulates pen/pencil ink bleeding and imperfect writing instruments\n",
        "- **Effect**: Adds slight blur to edges, creating more organic appearance\n",
        "- **Range**: 0 (no blur) to 3 (maximum blur)\n",
        "\n",
        "#### 4. **Background Variety**\n",
        "```python\n",
        "background_type=3         # Random background type\n",
        "```\n",
        "- **Background Types**:\n",
        "  - `0`: Gaussian noise\n",
        "  - `1`: Plain white\n",
        "  - `2`: Quasicrystal pattern\n",
        "  - `3`: Random selection from above options\n",
        "- **Purpose**: Enhances model robustness to different paper textures and scanning conditions\n",
        "\n",
        "#### 5. **Font Selection**\n",
        "```python\n",
        "fonts=font_paths          # Uses handwritten .ttf fonts from local directory\n",
        "```\n",
        "- **Purpose**: Foundation of handwriting simulation\n",
        "- **Critical**: MUST use actual handwritten-style fonts, not standard fonts\n",
        "- **Effect**: Each font represents a different \"handwriting style\"\n",
        "\n",
        "---\n",
        "\n",
        "##  Font Directory Structure\n",
        "\n",
        "### Required Setup:\n",
        "\n",
        "```\n",
        "project_root/\n",
        " PD1_ICR_V3.ipynb              # This notebook\n",
        " handwritten_fonts/            # CREATE THIS FOLDER\n",
        "    handwriting1.ttf\n",
        "    handwriting2.ttf\n",
        "    cursive_font.ttf\n",
        "    script_style.ttf\n",
        " dataset_handwritten_28x28/    # Generated automatically\n",
        "     A/\n",
        "        A_00001.png\n",
        "        A_00002.png\n",
        "        ...\n",
        "     B/\n",
        "        B_00001.png\n",
        "        ...\n",
        "     ...\n",
        "```\n",
        "\n",
        "### Recommended Handwritten Font Sources:\n",
        "\n",
        "1. **Google Fonts** (Free):\n",
        "   - Caveat\n",
        "   - Permanent Marker\n",
        "   - Indie Flower\n",
        "   - Shadows Into Light\n",
        "   - Patrick Hand\n",
        "   - Kalam\n",
        "   - Architect's Daughter\n",
        "\n",
        "2. **Download Process**:\n",
        "   ```bash\n",
        "   # Example: Download from Google Fonts\n",
        "   # 1. Visit: https://fonts.google.com/\n",
        "   # 2. Search for \"handwriting\" or \"script\" fonts\n",
        "   # 3. Download the font\n",
        "   # 4. Extract the .ttf file\n",
        "   # 5. Place it in ./handwritten_fonts/\n",
        "   ```\n",
        "\n",
        "3. **Naming Convention**:\n",
        "   - Font files can have any name (e.g., `my_handwriting.ttf`)\n",
        "   - The script automatically discovers all `.ttf` files in the folder\n",
        "   - Multiple fonts = greater handwriting variety in your dataset\n",
        "\n",
        "---\n",
        "\n",
        "##  Comparison: Handwritten vs Printed Simulation\n",
        "\n",
        "| Aspect | Printed (Default TRDG) | Handwritten (This Implementation) |\n",
        "|--------|------------------------|------------------------------------|\n",
        "| **Font** | System fonts (Arial, Times) | Handwritten .ttf fonts |\n",
        "| **Skewing** | None | 10 random slant |\n",
        "| **Distortion** | None | Sine wave distortion |\n",
        "| **Blur** | Sharp edges | Random blur (ink bleeding simulation) |\n",
        "| **Appearance** | Perfectly uniform | Irregular, organic |\n",
        "| **Real-world Use** | Typed documents | Human handwriting recognition |\n",
        "\n",
        "---\n",
        "\n",
        "##  Optimization Tips for Best Results:\n",
        "\n",
        "1. **Use 5-10 different handwritten fonts** for maximum variety\n",
        "2. **Adjust `BASE_SAMPLES_PER_LETTER`** based on requirements (1000-10000 recommended)\n",
        "3. **Image size**: 28x28 pixels optimal for single characters\n",
        "4. **Increase `ROTATION_RANGE`** to 20 for more dramatic slant variation\n",
        "5. **Increase `BLUR_RADIUS_RANGE`** to (0.5, 2.0) for older/low-quality document simulation\n",
        "6. **Enable OpenCV** for morphological operations (erosion/dilation) to enhance realism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqDfM_GE6bdk"
      },
      "source": [
        "##  Optional: Visualize Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TIIy49fp6bOU",
        "outputId": "0ad1e727-e6bc-431b-df40-6813b7f5233d"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DATASET VISUALIZATION AND FINAL REPORT\n",
        "# =============================================================================\n",
        "# This cell displays samples from the generated dataset and produces a\n",
        "# comprehensive report on generation including font download statistics\n",
        "# and class distribution.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def visualize_dataset_samples(\n",
        "    output_root: str,\n",
        "    letters: list,\n",
        "    num_samples: int = 5\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Display random samples from the generated dataset.\n",
        "\n",
        "    Args:\n",
        "        output_root (str): Root directory of the dataset.\n",
        "        letters (list): List of characters.\n",
        "        num_samples (int): Number of samples to display per letter.\n",
        "    \"\"\"\n",
        "    # Select 5 random letters for display\n",
        "    sample_letters = random.sample(letters, min(5, len(letters)))\n",
        "\n",
        "    fig, axes = plt.subplots(len(sample_letters), num_samples, figsize=(15, 3 * len(sample_letters)))\n",
        "    fig.suptitle('Handwritten Character Dataset Samples', fontsize=16, fontweight='bold')\n",
        "\n",
        "    for i, letter in enumerate(sample_letters):\n",
        "        letter_dir = Path(output_root) / letter\n",
        "\n",
        "        if not letter_dir.exists():\n",
        "            print(f\"[WARNING] Directory {letter_dir} not found\")\n",
        "            continue\n",
        "\n",
        "        # Get all images (PNG or JPG)\n",
        "        images = list(letter_dir.glob(\"*.png\")) + list(letter_dir.glob(\"*.jpg\"))\n",
        "\n",
        "        if not images:\n",
        "            print(f\"[WARNING] No images in {letter_dir}\")\n",
        "            continue\n",
        "\n",
        "        # Select random samples\n",
        "        sample_images = random.sample(images, min(num_samples, len(images)))\n",
        "\n",
        "        for j, img_path in enumerate(sample_images):\n",
        "            img = Image.open(img_path)\n",
        "\n",
        "            if len(sample_letters) == 1:\n",
        "                ax = axes[j]\n",
        "            else:\n",
        "                ax = axes[i, j]\n",
        "\n",
        "            ax.imshow(img, cmap='gray', vmin=0, vmax=255)\n",
        "            ax.axis('off')\n",
        "\n",
        "            if j == 0:\n",
        "                ax.set_title(f\"'{letter}'\", fontsize=12, fontweight='bold', loc='left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.92)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def generate_final_report(\n",
        "    output_root: str,\n",
        "    letters: list,\n",
        "    font_stats: dict = None\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Generate a comprehensive report on the produced dataset.\n",
        "\n",
        "    This report includes:\n",
        "    - Font download statistics\n",
        "    - Image distribution by class\n",
        "    - Augmentation parameters used\n",
        "    - Dataset quality metrics\n",
        "\n",
        "    Args:\n",
        "        output_root (str): Root directory of the dataset.\n",
        "        letters (list): List of generated characters.\n",
        "        font_stats (dict): Font download statistics (optional).\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"DATASET GENERATION FINAL REPORT\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Generation date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    # Section 1: Font statistics\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"SECTION 1: FONT ACQUISITION\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    fonts_dir = Path(FONTS_OUTPUT_DIR) if 'FONTS_OUTPUT_DIR' in dir() else Path(\"./handwritten_fonts\")\n",
        "    available_fonts = list(fonts_dir.glob(\"*.ttf\")) if fonts_dir.exists() else []\n",
        "\n",
        "    print(f\"  Font directory: {fonts_dir.absolute()}\")\n",
        "    print(f\"  Available fonts: {len(available_fonts)}\")\n",
        "\n",
        "    if font_stats:\n",
        "        print(f\"  Successful downloads: {font_stats.get('successful', 'N/A')}\")\n",
        "        print(f\"  Failed downloads: {font_stats.get('failed', 'N/A')}\")\n",
        "\n",
        "    if available_fonts:\n",
        "        print(\"\\n  Font list:\")\n",
        "        for font_path in available_fonts[:10]:\n",
        "            print(f\"    - {font_path.name}\")\n",
        "        if len(available_fonts) > 10:\n",
        "            print(f\"    ... and {len(available_fonts) - 10} more\")\n",
        "\n",
        "    # Section 2: Class distribution\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"SECTION 2: CLASS DISTRIBUTION\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    output_path = Path(output_root)\n",
        "    class_distribution = {}\n",
        "    total_images = 0\n",
        "\n",
        "    if output_path.exists():\n",
        "        for letter in letters:\n",
        "            letter_dir = output_path / letter\n",
        "            if letter_dir.exists():\n",
        "                count = len(list(letter_dir.glob(\"*.png\"))) + len(list(letter_dir.glob(\"*.jpg\")))\n",
        "                class_distribution[letter] = count\n",
        "                total_images += count\n",
        "\n",
        "    if class_distribution:\n",
        "        max_count = max(class_distribution.values())\n",
        "        min_count = min(class_distribution.values())\n",
        "        avg_count = total_images / len(class_distribution)\n",
        "\n",
        "        print(f\"  Total images: {total_images:,}\")\n",
        "        print(f\"  Number of classes: {len(class_distribution)}\")\n",
        "        print(f\"  Average per class: {avg_count:.1f}\")\n",
        "        print(f\"  Min/Max per class: {min_count} / {max_count}\")\n",
        "        print(f\"  Balance ratio: {max_count / min_count:.2f}x\")\n",
        "\n",
        "        # Text-based histogram\n",
        "        print(\"\\n  Distribution:\")\n",
        "        for letter in sorted(class_distribution.keys()):\n",
        "            count = class_distribution[letter]\n",
        "            bar_length = int((count / max_count) * 40)\n",
        "            bar = \"#\" * bar_length\n",
        "            marker = \"\"\n",
        "            if letter in ['I', 'F', 'G', 'K', 'Q', 'X', 'Z']:\n",
        "                marker = \" [AUGMENTED]\"\n",
        "            elif letter in ['O', 'S']:\n",
        "                marker = \" [REDUCED]\"\n",
        "            print(f\"    {letter}: {count:5d} |{bar}{marker}\")\n",
        "    else:\n",
        "        print(\"  [INFO] Dataset not yet generated\")\n",
        "\n",
        "    # Section 3: Augmentation parameters\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"SECTION 3: AUGMENTATION PARAMETERS\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    print(\"  Image specifications:\")\n",
        "    print(\"    - Size: 28x28 pixels\")\n",
        "    print(\"    - Mode: Grayscale ('L')\")\n",
        "    print(\"    - Background: 220-255 (light)\")\n",
        "    print(\"    - Text: 0-50 (dark)\")\n",
        "\n",
        "    print(\"\\n  Geometric augmentation:\")\n",
        "    print(\"    - Rotation: -15 to +15 degrees\")\n",
        "    print(\"    - Translation: -3 to +3 pixels\")\n",
        "    print(\"    - Scale: 60% to 85%\")\n",
        "\n",
        "    print(\"\\n  Stroke simulation:\")\n",
        "    print(\"    - Thickness: 1 to 4 pixels\")\n",
        "    print(\"    - Gaussian blur: 0.0 to 1.5\")\n",
        "    print(\"    - Gaussian noise: sigma=5.0\")\n",
        "    print(\"    - Morphological operations: 30% probability\")\n",
        "\n",
        "    print(\"\\n  Class balancing:\")\n",
        "    print(\"    - Underrepresented (x2.5): I, F, G, K, Q, X, Z\")\n",
        "    print(\"    - Overrepresented (x0.7): O, S\")\n",
        "    print(\"    - Standard (x1.0): Other characters\")\n",
        "\n",
        "    # Section 4: Generated files\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"SECTION 4: GENERATED FILES\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    print(f\"  Dataset directory: {output_path.absolute()}\")\n",
        "\n",
        "    if output_path.exists():\n",
        "        subdirs = [d for d in output_path.iterdir() if d.is_dir()]\n",
        "        print(f\"  Subdirectories: {len(subdirs)}\")\n",
        "\n",
        "        stats_file = output_path / \"generation_stats.txt\"\n",
        "        if stats_file.exists():\n",
        "            print(f\"  Statistics file: {stats_file}\")\n",
        "\n",
        "    # Section 5: Recommendations\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"SECTION 5: TRAINING RECOMMENDATIONS\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    print(\"  Recommended preprocessing:\")\n",
        "    print(\"    - Normalization: pixels / 255.0 (range [0, 1])\")\n",
        "    print(\"    - Reshape for CNN: (N, 28, 28, 1)\")\n",
        "    print(\"    - Label encoding: One-hot or LabelEncoder\")\n",
        "\n",
        "    print(\"\\n  Suggested CNN architecture:\")\n",
        "    print(\"    - Input: (28, 28, 1)\")\n",
        "    print(\"    - Conv2D -> BatchNorm -> ReLU -> MaxPool (x2-3)\")\n",
        "    print(\"    - Dropout: 0.25-0.5\")\n",
        "    print(\"    - Dense -> Softmax (26 classes)\")\n",
        "\n",
        "    print(\"\\n  Initial hyperparameters:\")\n",
        "    print(\"    - Optimizer: Adam (lr=0.001)\")\n",
        "    print(\"    - Loss: categorical_crossentropy\")\n",
        "    print(\"    - Batch size: 32-64\")\n",
        "    print(\"    - Epochs: 20-50 with EarlyStopping\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"END OF REPORT\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# EXECUTE REPORT\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Retrieve download statistics if available\n",
        "font_download_stats = download_stats if 'download_stats' in dir() else None\n",
        "\n",
        "# Generate final report\n",
        "generate_final_report(\n",
        "    output_root=OUTPUT_ROOT,\n",
        "    letters=LETTERS,\n",
        "    font_stats=font_download_stats\n",
        ")\n",
        "\n",
        "# Visualize samples (if dataset exists)\n",
        "output_dataset_path = Path(OUTPUT_ROOT)\n",
        "if output_dataset_path.exists() and any(output_dataset_path.iterdir()):\n",
        "    print(\"\\n[VISUALIZATION] Displaying dataset samples...\")\n",
        "    visualize_dataset_samples(OUTPUT_ROOT, LETTERS, num_samples=6)\n",
        "else:\n",
        "    print(\"\\n[INFO] Dataset not yet generated. Execute generation cells first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R_NUuyR1Dic"
      },
      "source": [
        "## Copy .zip File to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfSC67BaGXFZ",
        "outputId": "0c223b15-5f12-43fb-a692-50be7d972274"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive (authorization window will appear)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Put here the path to the file you downloaded in Colab\n",
        "# Example: '/content/dataset.zip' or just 'dataset.zip'\n",
        "source_file = 'dataset_complet_v2.zip'\n",
        "\n",
        "# Put here the folder where you want to save it in your Drive\n",
        "# '/content/drive/My Drive/' is the root of your Drive\n",
        "destination_folder = '/content/drive/My Drive/'\n",
        "# ---------------------\n",
        "\n",
        "# Create destination folder if it doesn't exist\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "    print(f\"Folder created: {destination_folder}\")\n",
        "\n",
        "# Copy file\n",
        "print(f\"Copying {source_file} to Drive in progress...\")\n",
        "try:\n",
        "    shutil.copy(source_file, destination_folder)\n",
        "    print(\" Success! File copied to your Google Drive.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\" Error: Source file '{source_file}' not found. Check the name.\")\n",
        "except Exception as e:\n",
        "    print(f\" An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIwqYQqb1Sgi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
